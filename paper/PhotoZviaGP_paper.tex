
%\documentclass[useAMS, usenatbib, fleqn]{mn2e}

% PRD specific
\documentclass[aps,prd,showpacs,superscriptaddress,groupedaddress]{revtex4}  % twocolumn submission
%\documentclass[aps,preprint,showpacs,superscriptaddress,groupedaddress]{revtex4}  % for double-spaced preprint
\usepackage{dcolumn}   % needed for some tables
\usepackage{bm}        % for math
% avoids incorrect hyphenation, added Nov/08 by SSR
\hyphenation{ALPGEN}
\hyphenation{EVTGEN}
\hyphenation{PYTHIA}

\usepackage{microtype}
\usepackage{aas_macros}
\usepackage{times}
%\usepackage{txfonts}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsbsy}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{xspace}
\usepackage{float}
\usepackage{caption}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{color}	
\usepackage[breaklinks, colorlinks, citecolor=blue, linkcolor=black, urlcolor=black]{hyperref}%with colours
%\usepackage{hyperref}%without colours


\input{macros.tex}



\newcommand{\todo}[1]{\textcolor{blue}{[TODO: #1]}}
\newcommand{\bl}[1]{\textcolor{blue}{[BL: #1]}}
\newcommand{\dwh}[1]{\textcolor{cyan}{[DWH: #1]}}

%\setlength{\skip\footins}{0.6cm}
%\interfootnotelinepenalty=10000
%\pagerange{\pageref{firstpage}--\pageref{lastpage}} \pubyear{2015}
%\def\LaTeX{L\kern-.36em\raise.3ex\hbox{a}\kern-.15em
%    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}
%\newtheorem{theorem}{Theorem}[section]


\begin{document}

 
%\title{Accurate \& physical photometric redshifts from heterogeneous, incomplete spectroscopic training}
%\title{Accurate \& physical photometric redshifts for deep galaxy and quasar surveys with heterogeneous training data}
\title{Data-driven, interpretable photometric redshifts % for galaxy and quasar surveys\\ 
with unrepresentative training data}

\author{Boris~Leistedt}
  \email{boris.leistedt@nyu.edu}
  \affiliation{Center for Cosmology and Particle Physics, Department of Physics, New York University, New York, NY 10003, USA}
  \affiliation{Einstein Fellow}
  
\author{David~W.~Hogg}
  \email{david.hogg@nyu.edu}
  \affiliation{Center for Cosmology and Particle Physics, Department of Physics, New York University, New York, NY 10003, USA}
  
  
\begin{abstract}
We present a new method for deriving photometric redshifts for deep galaxy and quasar surveys, based on a physical, data driven model of photometric flux measurements with a latent model of spectral energy distributions (SEDs).
This conceptually novel approach combines the advantages of machine learning and template fitting methods, and alleviates the need of acquiring representative training data or constructing detailed galaxy SED models. 
It involves constructing a latent space of template SEDs directly from the training data using a Gaussian Process, the kernel of which encodes the physics of cosmological redshift. 
The training data can consist of a combination of spectroscopic data sets which not need to overlap or involve the same instrument as the target photometric survey of interest. 
We consider the latest SDSS data and demonstrate that we obtain accurate redshift point estimates and probability distributions even with non representative training data. 
Finally, we show how this method addresses the computational challenges offered by ongoing and future photometric surveys, via the ability to quickly enhance the training data and re-calculate redshift probability distributions, for example.
\end{abstract}

\pacs{TODO}

\maketitle

  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Three main methods exist for obtaining redshifts from photometric fluxes, and all of them require external data.

In machine learning methods, the flux-redshift relation is fitted using a very flexible model which depends on the algorithm under consideration and has to be trained on the available training data (where spectroscopic redshifts are available).
This approach is very powerful for learning relationships in the data.
For this reason it usually provides excellent redshift estimates in the regions with good training data, even in the presence of imperfect fluxes (\ie biased or with underestimated errors).
In other words, in the interpolation regime, machine learning methods excel.
However, they perform poorly in regions with fewer or no training data, mostly because the constructed model is very flexible and gives more weight to dense training regions.
In addition, it does not know about the physics of redshift or fluxes. 
It will, of course, partially learn it from the training data, but because is not at all constrained to satisfy the physics of the problem, the flux-redshift model performs poorly when extrapolating outside of the training data.

A second method, template-fitting, directly addresses this problem. If a library of galaxy spectra (\ie templates for the spectral energy distributions of various galaxy types) is available, then one can solve for the redshift and type of a galaxy given the observed photometric fluxes.
A significant advantage over machine learning methods is the ability to perform the fit in a fully probabilistic fashion, with explicit priors over the types and redshifts of galaxies\footnote{While the outputs of some machine learning methods can be interpreted in probabilistic terms, most implicitly construct complicated priors from the training data and algorithm under consideration, making any probabilistic interpretation difficult.}.
While template fitting approaches provide an elegant solution to estimate photometric redshifts and also other galaxy properties (\eg star formation history), they are very restrictive compared to machine learning methods.
One the one hand, one has to assume that all the observed galaxies live in the space of spectral templates. 
While methods have been developed to relax this constrain (\eg by introducing correction terms to existing template libraries or adopting very flexible spectral template with numerous physical parameters) this is insufficient.
On the other hand, the complexity and imperfections of observed fluxes cannot easily be captured.
As a consequence of these two limitations, template fitting methods fail to provide reliable redshift estimates for deep photometric surveys.
The method presented here will solve both of those problems, while also harnessing the flexibility of machine learning.

The third class of methods for estimating photometric redshifts is referred to as ``clustering redshifts" and rely on spatial information to constrain the redshifts of galaxies.
It comes in several incarnations and can complement other redshift estimates, for example provided by the methods described above and also the method presented in this paper.
Given its different nature (using spatial information, not fluxes) and its complementarity with other methods, we will not discuss this in further detail.

%A robust solution to estimate photometric redshifts is to marginalise over the templates compatible with the training data, so that the photometric redshifts of much fainter galaxies only use that information in a physically meaningful way. 

The scope of this paper is as follows: we define a generic approach to use gaussian processes to fit fluxes and redshifts using kernels capturing the known physics of cosmological redshift.
We adopt specific kernels making this construction fast and flexible.


In what follows we will focus on galaxies although quasars and other extragalactic objects could be used.

The remainder of this paper is structured as follows: In \secref{sec:methods}, we present our novel \photoz inference method and we discuss its advantages and limitations. We illustrate its performances on real data in \secref{sec:data}. We conclude in \secref{sec:concl}. The Appendices of this paper provide more details about our implementation of the method.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Photometric redshift inference via physical Gaussian Processes}\label{sec:methods}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Background and assumptions}

\todo{add units}
For the purpose of this work, a galaxy is fully described by its rest-frame luminosity density or spectral energy distribution (SED), denoted by $L_\nu(\lambda_\mathrm{em})$ at the emitted wavelength $\lambda_\mathrm{em}$.
If this galaxy lies at redshift $z$, the energy density of the flux measured at redshift $0$ (\eg on Earth, in the absence of extra doppler shift terms) at a wavelength $\lambda_\mathrm{obs}$ reads
\equ{
	f_\nu(\lambda_\mathrm{obs}, z) = \frac{(1+z)}{4\pi D^2(z)}  \ L_\nu\left(\frac{\lambda_\mathrm{obs}}{1+z}\right)
}
where $D(z)$ is the luminosity distance. 
Three effects are in play here: the doppler shift of photons, the dimming of the flux due to distance, and its amplification due to the background expansion of the universe. 
We are interested in photometric measurements of the flux $f_\nu$, in a  set of bands $b=1, \dots, N_b$ described by a set of filter responses $\{ W_b(\lambda) \}$, which we assumed to be known.
The photometric flux measured in the $b$-th band is
\eqn{
	F_b(z) &=& \frac{(1+z) \ \ell}{4\pi D^2(z) g^\mathrm{AB} C_b}   \int_0^\infty f_\nu(\lambda_\mathrm{obs}, z) \ W_b(\lambda_\mathrm{obs}) \frac{\d\lambda_\mathrm{obs}}{\lambda_\mathrm{obs}}  \\
		&=& \frac{(1+z)^2 \ \ell}{4\pi D^2(z) g^\mathrm{AB} C_b}   \int_0^\infty L_\nu(\lambda_\mathrm{em}, z) \ V_b\bigl(\lambda_\mathrm{em}(1+z)\bigr) \ \d\lambda_\mathrm{em} \label{fluxredshift}
}

where $g^{AB}$ is the zero point of the AB photometric system, and $C_b$ is the filter normalization constant $C_b = \int_0^\infty W_b(\lambda) \d\lambda / \lambda$. The change of convention from $W_b$ to  $V_b(\lambda) = W_b(\lambda)/\lambda$ will make some of the calculations below easier.

We are interested in estimating the redshifts of a set of {\bf target galaxies}, for which we have noisy photometric flux measurements $\hat{\mat{F}}=(\hat{F}_1, \dots, \hat{F}_{N_b})$ with Gaussian errors ${\bf \sigma}_{\hat{F}}=(\sigma_{\hat{F}_1}, \dots, \sigma_{\hat{F}_{N_b}})$. 
We assume that a {\bf training set} is available, \ie an other set of galaxies with noisy photometric flux measurements, but where the redshifts are available (\eg via high measurement of the $f_\nu$ and subseqeunt estimation of the type and redshift of the object). 
We also assume that a set of template SEDs are available.
Standard machine learning methods would only rely on the training set, while template fitting methods would only exploit the SED template library to estimate the redshifts of the target galaxies.
The method presented here uses both the training set and the template SEDs, but is less sensitive to their redshift coverage and validity, unlike existing methods.

Note that we implicitly assume that there are no significant biases or outliers in the fluxes, flux errors, and spectroscopically confirmed redshifts, in both the training and target galaxy samples. 
However, these assumptions could be relaxed, as discussed below.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Inference}

As in template fitting methods, we introduce a variable $t$ labelling galaxy types or classes, described by a (continuous or discrete) ensemble of SEDs $L_\nu(\lambda, t)$, so that the the photometric flux becomes $F_b(z, t)$.
For a target galaxy of interest, the posterior distribution on its redshift given noisy photometric flux measurements $\hat{\mat{F}}$ is
\eqn{
	p(z | \hat{\mat{F}}) \propto \int \mathrm{d}t\  p\bigl(\hat{\mat{F}}| z, t\bigr)\ p(z, t)
  \approx \sum_{i} w_i \ p\bigl( \hat{\mat{F}}| z, t_i\bigr)
  }
 The discretization arises because we seek to model a finite number of types from a training set itself, with the weights capturing prior information. 
 The type $t_i$ is constructed from the $i$-th training galaxy, with noisy photometric fluxes $\hat{\mat{F}}_i$ and redshift $z_i$. 
 Hence, for each pair of target and training galaxies, we can compute 
 \eqn{ 
 	p\bigl(\hspace*{-2pt}\underbrace{\hat{\mat{F}}| z}_{\mathrm{target}}, t_i \bigr) &=& p\bigl(\hat{\mat{F}}| z, \underbrace{z_i, \hat{\mat{F}}_i}_{\mathrm{training}} \bigr) \\
	&=& p\bigl(\hat{\mat{F}}| \mat{F}(z, t_i)\bigr) \ p\bigl( \mat{F}(z, t_i)| z_i, \hat{\mat{F}}_i\bigr).\label{eq:traintarpair}
	}
The first term is the flux likelihood function, \eg a multivariate Gaussian in the case of Gaussian errors.
\equ{
	p\bigl(\hat{\mat{F}}| \mat{F}(z, t_i)\bigr) = \prod_b \mathcal{N}\left( \hat{F}_b - F_b(z, t_i); \sigma_{\hat{F}_b}  \right)
}
The extension to correlated flux errors is straightforward.
Note that this likelihood function could be improved by including more informative prior information about the absolute scaling of the template, but we don't consider this extension here.
\todo{Include model uncertainties and correct ell scaling in both parts of \eqref{eq:traintarpair}}
 \eqn{ 
 	p\bigl(\hspace*{-2pt}\underbrace{\hat{\mat{F}}| z}_{\mathrm{target}}, t_i \bigr) = p\bigl(\underbrace{\hat{\mat{F}}| \hat{\ell}, z}_\mathrm{target}, \underbrace{\hat{\mat{F}}_i, z_i, \hat{\ell}_i}_\mathrm{training} \bigr) 
	}
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Gaussian process in redshift-flux space}

The second term of \equref{eq:traintarpair} requires to use the noisy fluxes of the training galaxy $\hat{\mat{F}}_i$ at redshift $z_i$ and predict (noiseless) fluxes at a different redshift $z$.
An elegant way to address this problem could be to explore the set of SEDs compatible with the photometry $\hat{\mat{F}}_i$ at redshift $z_i$, then redshift those individually at redshift $z$, and compute the mean and variance of the predicted fluxes.
The SED model could be derived from a model of galaxy formation, data-driven templates, etc. 
However, this approach is computationally intractable since it requires to simulate large numbers of SEDs (\eg via a MCMC sampling method) and integrating those for comparison to each training galaxy and for predicting fluxes at several other redshifts. 
In addition, given the broadness of photometric bands and the typical flux errors, the predicted fluxes are most likely to be less sensitive to the details of the SED model.
To resolve these issues all at once, we will use a Gaussian Process $F(b, z) \sim \mathcal{GP}\bigl( \mu^F, \ k^F\bigr)$, and encode both the SED model and the physics of redshift in the mean function $\mu^F$ and the kernel $k^F$.

Gaussian Processes are a flexible model to fit noisy observations and make predictions, in both the interpolation and extrapolation regimes, with the uncertainties resulting from the fit.
When the likelihood function is Gaussian, most operations (including marginalization and posterior predictions) are analytically tractable, which makes them very appealing.
Their main drawback is the large matrix operations, which is not a problem here since we fit each training galaxy with a separate Gaussian Process (thus, the number of data points to fit is the number of photometric bands).
An excellent introduction to Gaussian Processes is provided in REF.

While classical mean functions and kernels could be used here, they would predict fluxes $F_b(z, t_i)$ that wouldn't correspond to an SED being redshifted.
Instead, we will impose the mean function $\mu^F$ and the kernel $k^F$ to capture the expected correlations across redshift and bands resulting from the know setup and physics of the problem: the bands have known responses $\{ W_b(\lambda)\}$, and galaxy SEDs are redshifted according to \equref{fluxredshift}.  
Concretely, we want to define a mean function and a kernel that implicitly solve the same procedure described above: constructing SEDs compatible with the $\hat{\mat{F}}_i$, redshifting and integrating them to obtain flux predictions $\mat{F}(z, t_i)$. 
It is possible under certain assumptions and descriptions of the SEDs, as described below.

We model the latent, underlying SED of each training galaxy as a linear sum of templates $T^k_\nu(\lambda)$ (\eg taken from a standard template fitting method) and residuals that take the form of a zero-mean Gaussian Process $R_\nu \sim \mathcal{GP}\bigl(0, k^\lambda(\lambda,\lambda') \bigr)$.
\eqn{
	L_\nu(\lambda, \bm{\alpha}, \ell) =  \underbrace{\sum_{k=1}^{N_T} \alpha_k\ T_\nu^k(\lambda)}_{\rm templates} + \ \underbrace{ \ell R_\nu(\lambda)}_{\rm residuals} \ \sim \ \mathcal{GP}\Bigl(\sum_k \alpha_k T^k_\nu(\lambda), \ \ell k(\lambda, \lambda')\Bigr)\nonumber
}
with $\bm{\alpha}=(\alpha_1, \dots, \alpha_{N_T})$ the template coefficients. 
$\ell$ is the absolute luminosity and allows us to scale the residuals for each galaxy. 

Propagating this model in \equref{fluxredshift}, we find that the photometric flux is also a Gaussian Process,
\equ{
	F_b(z, \bm{\alpha}, \ell) \sim \ \mathcal{GP}\Bigl( \mu^F(b, z, \bm{\alpha}), k^F(b,b',z,z',\ell,\ell')\Bigr).
	}
Note that we will marginalize over the $\bm{\alpha}$ coefficients and use a point estimate for $\ell$, as explained below.

It is straightforward to show that the mean function is
\eqn{
	\mu^F(b, z, \bm{\alpha}) = \frac{(1+z)^2 }{4\pi D^2(z)g^\mathrm{AB} C_b}  \sum_{k=1}^{N_T} \alpha_k \int_0^\infty T_\nu^k(\lambda) \ V_b\Bigl((1+z)\lambda\Bigr) \ {\d\lambda}   =   \sum_{k=1}^{N_T}  \alpha_k F^k_b(z) 
}
and does not depend on type or photometric band, where $F^k_b(z)$ is the $b$-th flux of the $k$-th template at redshift $z$.
The covariance function or kernel is
\eqn{
	k^F(b,b',z,z',\ell,\ell') &=& \left( \frac{ (1+z)(1+z') }{4\pi D(z) D(z') g^\mathrm{AB}} \right)^2  \frac{\ell\ell'}{C_bC_{b'}} \int_0^\infty \ V_b\Bigl((1+z)\lambda\Bigr) \ V_{b'}\Bigl((1+z')\lambda'\Bigr) \ k(\lambda, \lambda') \ \d\lambda\d\lambda' 
}.

This is the generic kernel for fluxes given a kernel in SED space. 
In general, it must be numerically evaluated, which can be challenging. 
But for some specific choices of $k$ and representations of $V_b$, close analytical forms will exist. 
We give such form in \appref{sec:rbfgp}, which we use in the remainder of this paper. 
It is based on a radial basis kernel $k\propto \exp(-\beta(\lambda-\lambda')^2)$ and approximations of the filter responses with Gaussian mixtures.

Now that we derived a suitable Gaussian Process, we can write $p\bigl( \mat{F}(z,t_i) | z_i, \hat{\mat{F}}_i\bigr)$ as the flux predictions when fitting the $i$-th training set galaxy. 
This is a standard Gaussian Process prediction, where we marginalize over the $\bm{\alpha}$ since with Gaussian priors then can be included in the GP. 
Both the prediction and marginalization procedures and standard and follow REF. 
We include the exact equations we solve in \appref{sec:gppred} for completeness.

\begin{figure}
\caption{GP applied to one simulated galaxy, compared to real spectrum}
\label{fig:simgpfluxes}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Discussion}

We first discuss the assumptions and limitations of our method.

\paragraph{Flux biases} 
We have assumed that the fluxes measurements are unbiased, and that their errors are Gaussian and correctly characterized.
However, real flux measurements and their error estimates display small magnitude-, type- and redshift-dependent biases.
Since this method is trained on real fluxes, it will absorb some of these biases. 
In addition, it is straightforward to add (hyper)parameters describing such biases, and fit or marginalize for those while training or applying the method.
In the data example below, we have included a parameter describing an extra flux error term to be added in quadrature to all flux errors.

\paragraph{Negative flux predictions}
In the description above, the latent SED and the fluxes are not constrained to be positive. 
However, this is not really a problem since the flux will go negative in regimes where the SED is not constrained.
The large errors will prevent those negative fluxes from having any effect on the results, since their contribution to the likelihood function is basically zero.

\paragraph{Use of galaxy spectra}
Our approach ignores the fact that for most training objects high(er) resolution spectroscopic measurements of $f_\nu$ are available, and that those could be used in the model. 
Some methods explicitly rely on available spectroscopic measurements to construct a latent space of template SEDs and produce photometric redshifts.
However, we decide to focus on photometric flux measurements and not to include high(er) resolution spectra for two reasons.
First, real fluxes don't always easily relate to SEDs via \eqref{fluxredshift}, for example due to the way they are measured and because of the non-uniform distribution of the light emission in galaxies. 
Having a data-driven model of the mapping between fluxes and SEDs as implemented in this method is a flexible way to overcome these issues.
Second, in the future, training sets will consists of many band data.

\bigskip
We now turn to the advantages of the novel approach presented here.

\paragraph{Heterogeneous, incomplete training sets} 
Use heterogeneous data sets

\paragraph{Machine learning with physical interpolation/extrapolation} 
Correct interpolation scheme incorporating the physics of the problem. 

\paragraph{Meaningful probabilities} 
Producing real probability distributions and very robust PDFs

\paragraph{Flexible (hyper)parameters}
 Hyperparameters and weighting can be optimized without affecting the rightness of the model, to optimize any quantity of interest: PDF robustness, N(z), etc.

\paragraph{New training data or use of other training sets}
 New training data can be added at virtually no cost. without 

\paragraph{Speed and storage}
 Massively parallel, very cheap recalculations of the PDF and no need to store them.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Demonstration on SDSS data}\label{sec:data}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Setup}

Description of data and GP setup/parameters.
Priors, luminosities, likelihood, 

\begin{figure}
\caption{GP applied to one galaxy, with predictions for DECALS}
\end{figure}

\begin{figure}
\caption{Scatter plot of zmean vs zspec for CWW and GP}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Results}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}\label{sec:concl}

Quasars

{Classification}
Star-quasar and star-galaxy separation

{Mapping to physical models}
2D Gaussian process for full template model interpolation.
Mapping onto SPS models.

Data augmentation for machine learning


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotesize{
  \bibliographystyle{mn2e_eprint}
\providecommand{\eprint}[1]{\href{http://arxiv.org/abs/#1}{arXiv:#1}}	
  \bibliography{bib}
}
\normalsize


\appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Our GP implementation and SED prior}\label{sec:rbfgp}

We model the relative energy density of luminosity of galaxies of type $t$ as a function of wavelength $\lambda$ as
\equ{
	R_\nu(\lambda) = C(\lambda) + \sum_{l} A(\lambda) \gaussian(\lambda, \lambda_l, \sigma_l)
}
where $C$ represent the continuum and $A$ the amplitude of Gaussian emission or absorption lines of fixed location and size $ \lambda_l, \sigma_l$ with $l = 1, \ldots, {\rm N}_{\rm lines}$. Both $C$ and $A$ are modeled as Gaussian Processes with factorized kernels
\eqn{
	C(\lambda) \sim \GP\left(0, k_C(\lambda, \lambda')\right)\\
	A(\lambda) \sim \GP\left(0, k_A(\lambda, \lambda')\right)
}
If one further assumes that $C$ and $A$ are uncorrelated, then 
\eqn{
	R_\nu(\lambda) \sim \GP\left(0, K_R(\lambda, \lambda')\right)
}
with 
\eqn{
	k_R(\lambda, \lambda') = K_C(\lambda, \lambda') + k^A(\lambda, \lambda')\sum_{l} \gaussian(\lambda, \lambda_l, \sigma_l) \gaussian(\lambda', \lambda_l, \sigma_l)
	}
assuming that the various lines $\gaussian(\lambda, \lambda_l, \sigma_l)$ don't overlap significantly so that cross terms can be neglected. All kernels are assumed to be a Gaussian, sometimes called Radial Basis Function (RBF) in the Gaussian Process litterature,
\eqn{
	K_C(\lambda, \lambda') &=&  V_C\  \mathcal{N}\left(\lambda, \lambda', {\alpha}_C\right) \\
	K_L(\lambda, \lambda') &=&  V_L\ \mathcal{N}\left(\lambda, \lambda', {\alpha}_L\right)
}

We approximate the rescaled filters $V_b(\lambda) = W_b(\lambda)/\lambda$ as a sum of Gaussian distributions,
\eqn{
	V_b(\lambda) = \sum_{i} a_{i}\mathcal{N}(\lambda,\mu_i,\sigma_i) \quad\quad  V_{b'}(\lambda) = \sum_{i'} a_{i'}\mathcal{N}(\lambda,\mu_{i'},\sigma_{i'})
}
We drop the secondary $b$ dependency below, but it should be understood that the $i$ and $j$ indices below depend on each band.
The kernel for our flux-redshift Gaussian Process is
\eqn{
	k(b,b',z,z',\ell,\ell') &=& \left( \frac{ (1+z)(1+z') }{4\pi D(z) D(z') g^\mathrm{AB}} \right)^2 \frac{\ell \ell'}{C_bC_{b'}} \nonumber \\
	  \times \ \sum_{i}\sum_{i'} a_{i} a_{i'} &&\hspace*{-5mm} \left( 2\pi\sigma_{i}\sigma_{i'} V_C\ K_C(z,z',b,b',i,i') + V_L \ \sum_{l}\sum_{l'} K_L(z,z',b,b',i,i',l,l')\right)
}
where the continuum kernel is
\eqn{
	K_C(z,z',b,b',i,i') = \frac{{\alpha}_C}{\sigma_{ii'}} \mathcal{N}\left( \mu_{i}(1+z'), \mu_{i'}(1+z), \sigma_{ii'}\right)
}	
with
\equ{
	\sigma_{ii'}^2 \ =\ \sigma_{i}^2(1+z')^2 + \sigma_{i'}^2(1+z)^2 + {\alpha}_C^2(1+z)^2(1+z')^2
}
and the line kernel is
\eqn{
	K_L(z,z',b,b',i,i',l,l') \ = \  \mathcal{N}\left( \mu_{i}, \mu_{l}(1+z), \sigma_{i}\right) \ \mathcal{N}\left( \mu_{i'}, \mu_{l'}(1+z'), \sigma_{i}\right) \ \mathcal{N}\left( \mu_{l}, \mu_{l'}, {\alpha_L}\right)
}	

Note that the kernel is non-stationary.

Finally, for the type dependence of the mean function, we set $\alpha(t) = \alpha_0 \ t$. \todo{Explain rationale}.

\todo{Describe hyperparameters}

So our full vector of hyperparameters is $\bm{\alpha} = (\alpha_0, \alpha_t, V_L,  \alpha_L, V_C, \alpha_C)$



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{GP predictions}\label{sec:gppred}

Start with assumptions, input data, output prediction on a grid, priors. Describe vectors one by one.
Secondly, we use a multivariate Gaussian prior on the template coefficients, $p(\bm{\alpha}) = \mathcal{N}(\vec{b}, \mat{B})$. For the inputs and outputs variables, we use the same notation as Rasmusssen and Williams. For this purpose, we define the following vectors and matrices:
\eqn{
	\mat{X} &=&  \\
	\mat{X^*} &=& \\
	\vec{y} &=& \\
	\vec{y}^* &=& \\
	\mat{K} &=& \\ 
	\mat{K}_y &=& \\
	\mat{K}^* &=& \\
	\mat{K}^{**} &=& \\
	\bm{\beta}* &=& \\
	\mat{H} &=& \\
	\mat{R} &=& 
}

\eqn{
	p( F_b(z, \ell) | z_i, \hat{\mat{F}}_i, \ell_i ) =  \mathcal{N}(\bar{F}_b(z), k(\vec{x}^*,\vec{x}^*)) \\ 
	\bar{f} \ =\  k(\vec{x}^*,\vec{x})[k(\vec{x},\vec{x}) + \sigma I]^{-1} \vec{y} = \sum_i \alpha_i(y_i) k(x_i,\vec{x}^*)
}


%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
